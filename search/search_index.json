{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83e\udde0 LLM Extractinator","text":"<p>\u26a0\ufe0f Prototype Warning: This tool is in active development and may change significantly. Always verify results!</p> <p>LLM Extractinator enables efficient extraction of structured data from unstructured text using large language models (LLMs). It supports flexible configuration, task setup, and can be used via both CLI and Python interface.</p> <p></p>"},{"location":"citation/","title":"\ud83d\udcdd Citation","text":"<p>If you use this tool, please cite:</p> <p>DOI: 10.5281/zenodo.15089764</p>"},{"location":"cli-usage/","title":"\ud83d\udcbb CLI Usage: <code>extractinate</code>","text":"<p>Below are the configurable input flags for the CLI tool:</p> Flag Type Default Description <code>--task_id</code> <code>int</code> Required Task ID to run <code>--run_name</code> <code>str</code> <code>\"run\"</code> Logging name <code>--n_runs</code> <code>int</code> <code>0</code> Number of runs <code>--num_examples</code> <code>int</code> <code>0</code> Examples per task <code>--num_predict</code> <code>int</code> <code>512</code> Max prediction tokens <code>--chunk_size</code> <code>int</code> <code>None</code> Chunk size <code>--overwrite</code> <code>bool</code> <code>False</code> Overwrite existing outputs <code>--translate</code> <code>bool</code> <code>False</code> Translate examples <code>--verbose</code> <code>bool</code> <code>False</code> Verbose output <code>--reasoning_model</code> <code>bool</code> <code>False</code> Use reasoning model <code>--model_name</code> <code>str</code> <code>\"phi4\"</code> Model name <code>--temperature</code> <code>float</code> <code>0.0</code> Generation temperature <code>--max_context_len</code> <code>str</code> <code>\"max\"</code> Context length behavior <code>--top_k</code> <code>int</code> <code>None</code> Top-K sampling <code>--top_p</code> <code>float</code> <code>None</code> Nucleus sampling <code>--seed</code> <code>int</code> <code>None</code> Random seed <code>--output_dir</code> <code>Path</code> <code>output/</code> Output directory <code>--task_dir</code> <code>Path</code> <code>tasks/</code> Task config directory <code>--log_dir</code> <code>Path</code> <code>output/</code> Log directory <code>--data_dir</code> <code>Path</code> <code>data/</code> Input data path <code>--example_dir</code> <code>Path</code> <code>examples/</code> Examples directory <code>--translation_dir</code> <code>Path</code> <code>translations/</code> Translation directory"},{"location":"configuration/","title":"\ud83d\udee0\ufe0f Task Configuration","text":"<p>Create a JSON task file in the <code>tasks/</code> folder using the following naming format:</p> <pre><code>TaskXXX_taskname.json\n</code></pre>"},{"location":"configuration/#required-fields","title":"\ud83d\udccc Required Fields","text":"<p>Your JSON file must include the following keys:</p> <ul> <li><code>Task</code>: Name of the task  </li> <li><code>Type</code>: Task type  </li> <li><code>Description</code>: Description of the task  </li> <li><code>Data_Path</code>: Filename of the dataset  </li> <li><code>Input_Field</code>: Column containing the text data  </li> <li><code>Parser_Format</code>: JSON format for the expected output  </li> </ul>"},{"location":"configuration/#optional-for-using-examples","title":"\ud83d\udd04 Optional (for using examples)","text":"<ul> <li><code>Example_Path</code>: Path to the file with examples to include in the prompt</li> </ul> <p>Note: If you're not using examples, simply omit the <code>Example_Path</code> field. Do not set it to an empty string!</p>"},{"location":"contributing/","title":"\ud83e\udd1d Enhancements and Contributions","text":"<p>We welcome improvements, new tasks, and feature additions!</p> <ul> <li>\ud83d\udee0\ufe0f Submit pull requests for bug fixes, features, or new task configurations  </li> <li>\ud83d\udcac Open an issue to discuss ideas or enhancements</li> </ul> <p>Thank you for contributing! \ud83d\udc99</p>"},{"location":"data-structure/","title":"\ud83e\uddfe Data Structure","text":"<p>Input files must be in CSV or JSON format.</p> <ul> <li> <p>\ud83d\udcc4 The text data must reside in the column specified by the <code>Input_Field</code>   (default: <code>\"text\"</code>).</p> </li> <li> <p>\ud83d\udcc2 The path to the dataset is set in the <code>Data_Path</code> field   (default location: <code>data/</code> folder).</p> </li> <li> <p>\ud83d\udd01 If using examples (<code>num_examples &gt; 0</code>), specify the file in <code>Example_Path</code>   (default location: <code>data/</code>, configurable via the <code>--example_dir</code> flag).</p> </li> </ul>"},{"location":"installation/","title":"\ud83d\ude80 Installation Guide","text":"<p>Follow these steps to install and use the tool:</p>"},{"location":"installation/#1-install-ollama","title":"1. Install Ollama","text":""},{"location":"installation/#on-linux","title":"On Linux:","text":"<pre><code>curl -fsSL https://ollama.com/install.sh | sh\n</code></pre>"},{"location":"installation/#on-windows-or-macos","title":"On Windows or macOS:","text":"<p>Download the installer from: https://ollama.com/download</p>"},{"location":"installation/#2-install-the-package","title":"2. Install the Package","text":"<p>You have two options:</p>"},{"location":"installation/#option-a-install-from-pypi","title":"\ud83d\udd39 Option A \u2013 Install from PyPI:","text":"<pre><code>pip install llm_extractinator\n</code></pre>"},{"location":"installation/#option-b-install-from-a-local-clone","title":"\ud83d\udd39 Option B \u2013 Install from a Local Clone:","text":"<pre><code>git clone https://github.com/DIAGNijmegen/llm_extractinator.git\ncd llm_extractinator\npip install -e .\n</code></pre>"},{"location":"running/","title":"\u25b6\ufe0f Running the Extractinator","text":""},{"location":"running/#using-the-command-line","title":"\ud83d\udcdf Using the Command Line","text":"<pre><code>extractinate --task_id 001 --model_name \"phi4\"\n</code></pre>"},{"location":"running/#using-the-function-in-python","title":"\ud83d\udc0d Using the Function in Python","text":"<pre><code>from llm_extractinator import extractinate\n\nextractinate(\n    task_id=1,\n    model_name=\"phi4\"\n)\n</code></pre>"}]}