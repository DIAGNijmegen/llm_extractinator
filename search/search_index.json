{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83e\udde0 LLM Extractinator","text":"<p>\u26a0\ufe0f Prototype Warning: This tool is in active development and may change significantly. Always verify results!</p> <p>LLM Extractinator enables efficient extraction of structured data from unstructured text using large language models (LLMs). It supports flexible configuration, task setup, and can be used via both CLI and Python interface.</p> <p></p>"},{"location":"citation/","title":"\ud83d\udcdd Citation","text":"<p>If you use this tool, please cite:</p> <p>DOI: 10.5281/zenodo.15089764</p>"},{"location":"cli-usage/","title":"\ud83d\udcbb CLI Usage: <code>extractinate</code>","text":"<p>Below are the configurable input flags for the CLI tool:</p> Flag Type Default Description <code>--task_id</code> <code>int</code> Required Task ID to run <code>--run_name</code> <code>str</code> <code>\"run\"</code> Logging name <code>--n_runs</code> <code>int</code> <code>0</code> Number of runs <code>--num_examples</code> <code>int</code> <code>0</code> Examples per task <code>--num_predict</code> <code>int</code> <code>512</code> Max prediction tokens <code>--chunk_size</code> <code>int</code> <code>None</code> Chunk size <code>--overwrite</code> <code>bool</code> <code>False</code> Overwrite existing outputs <code>--translate</code> <code>bool</code> <code>False</code> Translate examples <code>--verbose</code> <code>bool</code> <code>False</code> Verbose output <code>--reasoning_model</code> <code>bool</code> <code>False</code> Use reasoning model <code>--model_name</code> <code>str</code> <code>\"phi4\"</code> Model name <code>--temperature</code> <code>float</code> <code>0.0</code> Generation temperature <code>--max_context_len</code> <code>str</code> <code>\"max\"</code> Context length behavior <code>--top_k</code> <code>int</code> <code>None</code> Top-K sampling <code>--top_p</code> <code>float</code> <code>None</code> Nucleus sampling <code>--seed</code> <code>int</code> <code>None</code> Random seed <code>--output_dir</code> <code>Path</code> <code>output/</code> Output directory <code>--task_dir</code> <code>Path</code> <code>tasks/</code> Task config directory <code>--log_dir</code> <code>Path</code> <code>output/</code> Log directory <code>--data_dir</code> <code>Path</code> <code>data/</code> Input data path <code>--example_dir</code> <code>Path</code> <code>examples/</code> Examples directory <code>--translation_dir</code> <code>Path</code> <code>translations/</code> Translation directory"},{"location":"configuration/","title":"\ud83d\udee0\ufe0f Task Configuration","text":"<p>Create a JSON task file in the <code>tasks/</code> folder using the following naming format:</p> <pre><code>TaskXXX_taskname.json\n</code></pre>"},{"location":"configuration/#required-fields","title":"\ud83d\udccc Required Fields","text":"<p>Your JSON file must include the following keys:</p> <ul> <li><code>Description</code>: Description of the task  </li> <li><code>Data_Path</code>: Filename of the dataset  </li> <li><code>Input_Field</code>: Column containing the text data  </li> <li><code>Parser_Format</code>: The filename of the file containing the parser format in the <code>tasks/parsers/</code> folder</li> </ul>"},{"location":"configuration/#about-parser_format","title":"\ud83d\udd0d About <code>Parser_Format</code>","text":"<p>This field should reference a Python file located in <code>tasks/parsers/</code> which defines a Pydantic model called <code>OutputParser</code>.</p> <p>This file is usually created using the <code>build-parser</code> tool. It must contain a class named <code>OutputParser</code>, which will be used by the LLM to structure its response into a valid JSON object.</p> <p>You may define other nested models to keep the schema organized, but <code>OutputParser</code> is the root that the system will rely on.</p>"},{"location":"configuration/#example","title":"Example:","text":"<pre><code>\"Parser_Format\": \"product_parser.py\"\n</code></pre> <p>The file <code>tasks/parsers/product_parser.py</code> might look like:</p> <pre><code>from pydantic import BaseModel\n\nclass Product(BaseModel):\n    name: str\n    price: float\n\nclass OutputParser(BaseModel):\n    products: list[Product]\n</code></pre>"},{"location":"configuration/#optional-for-using-examples","title":"\ud83d\udd04 Optional (for using examples)","text":"<ul> <li><code>Example_Path</code>: Path to the file with examples to include in the prompt</li> </ul> <p>Note: If you're not using examples, simply omit the <code>Example_Path</code> field. Do not set it to an empty string!</p>"},{"location":"contributing/","title":"\ud83e\udd1d Enhancements and Contributions","text":"<p>We welcome improvements, new tasks, and feature additions!</p> <ul> <li>\ud83d\udee0\ufe0f Submit pull requests for bug fixes, features, or new task configurations  </li> <li>\ud83d\udcac Open an issue to discuss ideas or enhancements</li> </ul> <p>Thank you for contributing! \ud83d\udc99</p>"},{"location":"data-structure/","title":"\ud83e\uddfe Data Structure","text":"<p>Input files must be in CSV or JSON format.</p> <ul> <li> <p>\ud83d\udcc4 The text data must reside in the column specified by the <code>Input_Field</code>   (default: <code>\"text\"</code>).</p> </li> <li> <p>\ud83d\udcc2 The path to the dataset is set in the <code>Data_Path</code> field   (default location: <code>data/</code> folder).</p> </li> <li> <p>\ud83d\udd01 If using examples (<code>num_examples &gt; 0</code>), specify the file in <code>Example_Path</code>   (default location: <code>data/</code>, configurable via the <code>--example_dir</code> flag).</p> </li> </ul>"},{"location":"installation/","title":"\ud83d\ude80 Installation Guide","text":"<p>Follow these steps to install and use the tool:</p>"},{"location":"installation/#1-install-ollama","title":"1. Install Ollama","text":""},{"location":"installation/#on-linux","title":"On Linux:","text":"<pre><code>curl -fsSL https://ollama.com/install.sh | sh\n</code></pre>"},{"location":"installation/#on-windows-or-macos","title":"On Windows or macOS:","text":"<p>Download the installer from: https://ollama.com/download</p>"},{"location":"installation/#2-install-the-package","title":"2. Install the Package","text":"<p>You have two options:</p>"},{"location":"installation/#option-a-install-from-pypi","title":"\ud83d\udd39 Option A \u2013 Install from PyPI:","text":"<pre><code>pip install llm_extractinator\n</code></pre>"},{"location":"installation/#option-b-install-from-a-local-clone","title":"\ud83d\udd39 Option B \u2013 Install from a Local Clone:","text":"<pre><code>git clone https://github.com/DIAGNijmegen/llm_extractinator.git\ncd llm_extractinator\npip install -e .\n</code></pre>"},{"location":"parser/","title":"\ud83d\udee0\ufe0f <code>build-parser</code> \u2013 Interactive Pydantic Model Builder","text":"<p>The <code>build-parser</code> command launches an intuitive web-based tool to visually create Pydantic v2 models\u2014without writing a single line of code. It's great for designing OutputParser formats, structured data schemas, or simply organizing typed data models.</p>"},{"location":"parser/#getting-started","title":"\ud83d\ude80 Getting Started","text":"<p>Make sure your Python package is installed in an environment where the CLI is available. Then, simply run:</p> <pre><code>build-parser\n</code></pre> <p>This command launches a local Streamlit app in your browser.</p>"},{"location":"parser/#outputparser-root-model","title":"\ud83d\udce6 OutputParser Root Model","text":"<p>At the core of this tool is the <code>OutputParser</code> class. This is the primary model used by the LLM in your framework to parse outputs into structured JSON.</p> <p>You always start with the <code>OutputParser</code> model, and build its fields just like any Pydantic model. You can then create additional models to use as nested types or components within <code>OutputParser</code>.</p> <p>This approach supports building complex, hierarchical schemas using composition and reuse.</p>"},{"location":"parser/#interface-overview","title":"\ud83e\uddf1 Interface Overview","text":""},{"location":"parser/#model-manager-sidebar","title":"\ud83e\udded Model Manager (Sidebar)","text":"<p>The Model Manager allows you to create additional models beyond <code>OutputParser</code>.</p>"},{"location":"parser/#why-is-this-useful","title":"Why is this useful?","text":"<p>Often, structured outputs require nested objects or repeated elements. Instead of defining everything flatly in <code>OutputParser</code>, you can:</p> <ul> <li>Break down your schema into logical subcomponents</li> <li>Reuse those components across multiple fields</li> <li>Keep your data models clean, readable, and maintainable</li> </ul>"},{"location":"parser/#example","title":"Example:","text":"<p>You could define a <code>Product</code> model and use it as a field in <code>OutputParser</code> like:</p> <pre><code>class OutputParser(BaseModel):\n    products: list[Product]\n</code></pre>"},{"location":"parser/#how-to-use-it","title":"How to use it:","text":"<ul> <li>Enter a model name (e.g., <code>Product</code>, <code>Metadata</code>)</li> <li>Click \u2795 Add model</li> <li>Names must begin with a capital letter and be valid Python identifiers</li> </ul>"},{"location":"parser/#design-tab","title":"\ud83c\udfd7\ufe0f Design Tab","text":"<p>Use this section to add fields to <code>OutputParser</code> and any other models you've created.</p> <ul> <li>Field name</li> <li>Field type (primitive, special type, or reference to another model)</li> <li>Mark as <code>Optional</code> if needed</li> <li>Provide subtypes for <code>list</code>/<code>dict</code>, or values for <code>Literal</code></li> </ul>"},{"location":"parser/#code-tab","title":"\ud83d\udcdd Code Tab","text":"<p>This shows the full generated code using Pydantic v2:</p> <ul> <li>Starts with the <code>OutputParser</code> model</li> <li>Includes any additional models you\u2019ve defined</li> </ul>"},{"location":"parser/#export-tab","title":"\ud83d\udcbe Export Tab","text":"<p>Choose to either:</p> <ul> <li>Download the generated code as a <code>.py</code> file</li> <li>Or save directly to <code>tasks/parsers/</code> inside your project</li> </ul>"},{"location":"parser/#example_1","title":"\ud83e\uddea Example","text":"<p>Let\u2019s say you want to extract a list of products from LLM output:</p> <ol> <li>Define a model called <code>Product</code> with fields like:</li> <li><code>name</code>: <code>str</code></li> <li><code>price</code>: <code>float</code></li> <li>In <code>OutputParser</code>, add:</li> <li><code>products</code>: <code>list[Product]</code></li> </ol> <p>Resulting code:</p> <pre><code>from pydantic import BaseModel\n\nclass Product(BaseModel):\n    name: str\n    price: float\n\nclass OutputParser(BaseModel):\n    products: list[Product]\n</code></pre>"},{"location":"parser/#output-location","title":"\ud83d\udcc1 Output Location","text":"<p>If you choose \"Save to <code>tasks/parsers/</code>\", your file will be saved at:</p> <pre><code>&lt;project-root&gt;/tasks/parsers/&lt;filename&gt;.py\n</code></pre>"},{"location":"running/","title":"\u25b6\ufe0f Running the Extractinator","text":""},{"location":"running/#using-the-command-line","title":"\ud83d\udcdf Using the Command Line","text":"<pre><code>extractinate --task_id 001 --model_name \"phi4\"\n</code></pre>"},{"location":"running/#using-the-function-in-python","title":"\ud83d\udc0d Using the Function in Python","text":"<pre><code>from llm_extractinator import extractinate\n\nextractinate(\n    task_id=1,\n    model_name=\"phi4\"\n)\n</code></pre>"}]}